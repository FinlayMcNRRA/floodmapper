{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6f2b34-9160-487f-8149-330aea68c6de",
   "metadata": {},
   "source": [
    "# Database Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b9610-bb5b-4f70-bd6e-ab3190a4a5a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# LGAS Table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47064131-a6ca-458d-95f6-27642d892161",
   "metadata": {},
   "source": [
    "CREATE TABLE public.lgas_info (\n",
    "\tlga_code22 int4 NOT NULL,\n",
    "\tlga_name22 varchar NOT NULL,\n",
    "\tste_code21 int4 NULL,\n",
    "\tste_name21 varchar NULL,\n",
    "\taus_code21 varchar NULL,\n",
    "\taus_name21 varchar NULL,\n",
    "\tareasqkm float4 NULL,\n",
    "\tloci_uri21 varchar NULL,\n",
    "\tshape_leng float4 NULL,\n",
    "\tshape_area float4 NULL,\n",
    "\tgeometry_col public.geometry(geometry, 25832) NULL,\n",
    "\tCONSTRAINT lgas_info_sample_pkey PRIMARY KEY (lga_name22)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ee6d0-8774-4a3d-8b84-5c5a1893f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ogr2ogr -lco GEOMETRY_NAME=geom -nln <table_name> Pg:'dbname=<db_name> host=<host_ip> user=<db username> port=<db port> password=<db password>'  lgas_info_last.geojson -append"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5312ca68-72a2-4d34-9e58-9c9f6c5cfd17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# GRIDS Table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dec00d25-060c-4887-a130-fc8ac7faf929",
   "metadata": {},
   "source": [
    "CREATE TABLE grid_loc (\n",
    "\togc_fid int4 NOT NULL DEFAULT nextval('grid_loc_sample_ogc_fid_seq1'::regclass),\n",
    "\t\"name\" varchar NULL,\n",
    "\tlga_name22 varchar NULL,\n",
    "\tgeometry public.geometry(polygon, 4326) NULL,\n",
    "\tCONSTRAINT grid_loc_sample_pkey1 PRIMARY KEY (ogc_fid)\n",
    ");\n",
    "\n",
    "CREATE INDEX grid_loc_sample_geometry_geom_idx ON public.grid_loc USING gist (geometry);\n",
    "\n",
    "ALTER TABLE public.grid_loc ADD CONSTRAINT lgas_info FOREIGN KEY (lga_name22) REFERENCES public.lgas_info(lga_name22);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53811711-d5a7-430a-b28c-650e5eefa36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ogr2ogr -lco GEOMETRY_NAME=geometry -nln <table_name> Pg:'dbname=<db_name> host=<host_ip> user=<db username> port=<db port> password=<db password>' all_grids_loc.geojson -overwrite / -append"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d706a-c75c-4272-afed-4bf155cec27d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Image Download Table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12292499-5f12-47ab-861d-d380d8ebe51a",
   "metadata": {},
   "source": [
    "CREATE TABLE images_download (\n",
    "\timage_id varchar NOT NULL,\n",
    "\tname varchar NULL,\n",
    "\tsatellite varchar NULL,\n",
    "\tdate date NULL,\n",
    "\tdatetime varchar NULL,\n",
    "\tdownloaded bool NULL,\n",
    "\tgcp_filepath varchar NULL,\n",
    "\tcloud_probability float8 NULL,\n",
    "\tvalids float8 NULL,\n",
    "\tsolardatetime varchar NULL,\n",
    "\tsolarday date NULL,\n",
    "\tin_progress int4 NULL DEFAULT 0,\n",
    "\tCONSTRAINT imgs_download_pk PRIMARY KEY (image_id)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e4147801-d1c5-4cb7-9e35-0d3585a08d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "import shapely.wkt\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1e73662-241a-44b6-bcec-10f1ac511c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem(\"gs\", requester_pays = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b502586-38f6-4396-9c75-8b9d02a37df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc06519b-5005-410c-b9ce-1fc04d5187e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfe9366d98747df89e5c941df7e0559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List all files available in GCP\n",
    "\n",
    "#GRID\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "blobs = client.list_blobs(\"ml4floods_nema\", prefix = \"0_DEV/1_Staging/GRID\")\n",
    "\n",
    "files = [x.name for x in tqdm(blobs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5a8b1de-eb59-4610-b847-57e9e93eea7e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a915d2977cf64936b4cc97b1949720cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rz/3bnyyjw92qggqckc99r0_9cc0000gn/T/ipykernel_9873/2970062231.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_img['image_id'] = df_img.apply(img_id, axis=  1)\n",
      "/var/folders/rz/3bnyyjw92qggqckc99r0_9cc0000gn/T/ipykernel_9873/2970062231.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_img['gcp_filepath'] = \"gs://ml4floods_nema/\" + df_img['fpath']\n"
     ]
    }
   ],
   "source": [
    "#Categorize into their respective collections\n",
    "\n",
    "\n",
    "def img_id(row):\n",
    "    return '_'.join([row['grid'], row['sat'], row['date']])\n",
    "\n",
    "sat_names = ['Landsat', 'PERMANENTWATERJRC', 'S2']\n",
    "\n",
    "results = []\n",
    "for f in tqdm(fnames):\n",
    "    m = f.split('/')\n",
    "    if not len(m) < 5:\n",
    "        m = m[3:]\n",
    "        if m[1] in sat_names:\n",
    "            grid = m[0]\n",
    "            sat = m[1]\n",
    "            file = m[2]\n",
    "            results.append(dict(grid= grid, sat = sat, file = file, date = file.split('.')[0], fpath = f))\n",
    "            \n",
    "dff = pd.DataFrame(results)\n",
    "\n",
    "#Split into two dataframes - one for image files, one for CSVs containing cloud/valids metadata.\n",
    "df_img = dff[dff['file'].str.contains('tif')]\n",
    "df_info = dff[dff['file'].str.contains('csv')]\n",
    "\n",
    "#image_id = grid_collection_date . example : GRID05011_S2_2022-10-22\n",
    "df_img['image_id'] = df_img.apply(img_id, axis=  1)\n",
    "df_img.columns = ['name', 'satellite', 'file', 'date', 'fpath', 'image_id']\n",
    "df_img['gcp_filepath'] = \"gs://ml4floods_nema/\" + df_img['fpath']\n",
    "images_table = df_img[['image_id', 'name', 'satellite', 'date', 'gcp_filepath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba07e4a-2b23-46b1-ae23-50fd1846e7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d9b787a-5fb5-4523-bcfa-bd6ec08773ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18286fd1159144a3a0dd90ec9c17e3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82593, 9)\n"
     ]
    }
   ],
   "source": [
    "# Read all CSVs, and concat into one dataframe\n",
    "\n",
    "def read_df(i):\n",
    "    path = \"gs://ml4floods_nema/{}\".format(df_info.iloc[i]['fpath'])\n",
    "    temp_df = pd.read_csv(path)\n",
    "    temp_df['grid'] = df_info.iloc[i]['grid']\n",
    "    temp_df['sat'] = df_info.iloc[i]['sat']\n",
    "    temp_df['date'] = temp_df['datetime'].str.split(' ').str[0]\n",
    "    temp_df['gcs_filepath'] = \"https://storage.cloud.google.com/ml4floods_nema/{}\".format(df_info.iloc[i]['fpath'])\n",
    "    return temp_df\n",
    "\n",
    "\n",
    "result = Parallel(n_jobs=12, backend=\"threading\")(\n",
    "        delayed(read_df)(i)\n",
    "        for i in tqdm(range(len(df_info)))\n",
    "    )\n",
    "\n",
    "\n",
    "all_info_sat = pd.concat(result)\n",
    "print(all_info_sat.shape)\n",
    "all_info_sat.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "#Rename columns\n",
    "all_info_sat.columns = ['system:time_start', 'valids', 'cloud_probability', 'datetime',\n",
    "       'index_image_collection', 'name', 'satellite', 'date', 'gcs_filepath']\n",
    "sat_dedup = all_info_sat.drop_duplicates(subset=['name', 'satellite', 'date'], keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2df7ce6d-defa-4f2c-9465-14f04d35cc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82593, 9), (81212, 9))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_info_sat.shape, sat_dedup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c3d7eff-c2b8-49df-9e75-8ba6d86dd0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    61068\n",
       "True     22704\n",
       "Name: downloaded, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_download = pd.merge(sat_dedup[['valids', 'cloud_probability','datetime','name', 'satellite', 'date']], df_img[['name', 'satellite', 'date', 'image_id', 'gcp_filepath']],  how = 'outer', on = ['date', 'name', 'satellite'])\n",
    "invalid_s2_indices = image_download[(image_download['valids'].isna()) & (image_download['satellite'] != 'PERMANENTWATERJRC')].index\n",
    "image_download = image_download.drop(invalid_s2_indices)\n",
    "image_download['downloaded'] = image_download['image_id'].apply(lambda x : True if pd.notna(x) else False)\n",
    "\n",
    "image_download['downloaded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c347cd19-967b-48f1-a7df-8e10b1c31897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2262f9a466104b2ab4db8e84648abaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83772 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calculate Solarday and solardatetime\n",
    "\n",
    "import geopandas as gpd\n",
    "grids = gpd.read_file('all_grids_loc.geojson')\n",
    "# grids = gpd.read_csv('grid_loc.csv')\n",
    "grids_dedup = grids.drop_duplicates(subset = 'name', keep = 'first')\n",
    "\n",
    "mmdf = pd.merge(image_download, grids_dedup, on = 'name', how = 'left')\n",
    "\n",
    "\n",
    "def solarday_calc(row):\n",
    "    if pd.notna(row['geometry']):\n",
    "        geom = row['geometry']\n",
    "        # geom = shapely.wkt.loads(row['geometry'])\n",
    "        longitude = geom.centroid.coords[0][0]\n",
    "        hours_add = longitude * 12 / 180.\n",
    "        # if pd.isna(row['datetime']):\n",
    "            # return row\n",
    "        if row['satellite'] in ['S2', 'Landsat']:\n",
    "            dt = parser.parse(row[\"datetime\"])\n",
    "            row['solardatetime'] = dt + timedelta(hours=hours_add)\n",
    "            row['solarday'] = row['solardatetime'].strftime(\"%Y-%m-%d\")\n",
    "            \n",
    "        return row\n",
    "    else:\n",
    "        return row\n",
    "    \n",
    "mmdf = mmdf.progress_apply(solarday_calc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82a500a4-2af9-4a27-bc6c-1847fb1816e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     73869\n",
       "False     9903\n",
       "Name: date_match, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysis of how many entries dont have matching UTC datetime and solardatetime\n",
    "\n",
    "def date_solar_match(row):\n",
    "    if row['solarday']:\n",
    "        return row['date'] == row['solarday']\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "mmdf['date_match'] = mmdf.apply(date_solar_match, axis = 1)\n",
    "mmdf['date_match'].value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6149bc1f-bbb8-45f9-904d-ffb0202de265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293db2d9f7344906a2441053ed1c3467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83772 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rz/3bnyyjw92qggqckc99r0_9cc0000gn/T/ipykernel_9873/1339013083.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mmdf['image_id'] = mmdf.progress_apply(apply_image_id, axis = 1)\n"
     ]
    }
   ],
   "source": [
    "def apply_image_id(row):\n",
    "    if pd.isna(row['image_id']):\n",
    "        if pd.notna(row['name']):\n",
    "            return \"_\".join([row['name'], row['satellite'], row['date']])\n",
    "    return row['image_id']\n",
    "\n",
    "#Rearranging columns and adding image_id if not present. \n",
    "\n",
    "mmdf = mmdf[['image_id', 'name', 'satellite', 'date', 'datetime' ,'gcp_filepath', 'valids', 'cloud_probability', 'solardatetime', 'solarday', 'downloaded']]\n",
    "mmdf['image_id'] = mmdf.progress_apply(apply_image_id, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5cb9f6e5-df99-47d0-a983-ba5d0e8245c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6ad17c9bd74afabd85abf6fcb3ed71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83772 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def change_date(row):\n",
    "    if row['satellite'] != 'PERMANENTWATERJRC' and row['date'] != row['solarday']:\n",
    "        if pd.notna(row['gcp_filepath']):\n",
    "            row['to_delete'] = True\n",
    "            row['date'] = row['solarday']\n",
    "            row['to_delete_url'] = row['gcp_filepath']\n",
    "            row['gcp_filepath'] = None\n",
    "            row['downloaded'] = False\n",
    "            row['image_id'] = \"_\".join([row['name'], row['satellite'], row['date']])\n",
    "        else:\n",
    "            row['date'] = row['solarday']\n",
    "            row['image_id'] = \"_\".join([row['name'], row['satellite'], row['date']])\n",
    "    return row\n",
    "\n",
    "#Changing dates for those where UTC and solardatetime dont match. \n",
    "mmdf = mmdf.progress_apply(change_date, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad92fa12-4d73-44b2-8d44-9a4bfa0b0f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rz/3bnyyjw92qggqckc99r0_9cc0000gn/T/ipykernel_9873/21118546.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  image_download_table['in_progress'] = 0\n"
     ]
    }
   ],
   "source": [
    "image_download_table = mmdf[['image_id', 'name', 'satellite', 'date', 'datetime', 'downloaded', 'gcp_filepath', 'cloud_probability', 'valids', 'solardatetime', 'solarday']]\n",
    "image_download_table['in_progress'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78d69504-b962-4bf0-a02b-407c51641c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>name</th>\n",
       "      <th>satellite</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>downloaded</th>\n",
       "      <th>gcp_filepath</th>\n",
       "      <th>cloud_probability</th>\n",
       "      <th>valids</th>\n",
       "      <th>solardatetime</th>\n",
       "      <th>solarday</th>\n",
       "      <th>in_progress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRID02947_Landsat_2022-08-21</td>\n",
       "      <td>GRID02947</td>\n",
       "      <td>Landsat</td>\n",
       "      <td>2022-08-21</td>\n",
       "      <td>2022-08-21 00:22:44.081500+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2022-08-21 09:46:36.471340+00:00</td>\n",
       "      <td>2022-08-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRID02947_Landsat_2022-09-06</td>\n",
       "      <td>GRID02947</td>\n",
       "      <td>Landsat</td>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>2022-09-06 00:22:45.466500+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.948793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2022-09-06 09:46:37.856340+00:00</td>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRID02947_Landsat_2022-10-08</td>\n",
       "      <td>GRID02947</td>\n",
       "      <td>Landsat</td>\n",
       "      <td>2022-10-08</td>\n",
       "      <td>2022-10-08 00:22:46.536500+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.371418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2022-10-08 09:46:38.926340+00:00</td>\n",
       "      <td>2022-10-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRID02947_Landsat_2022-08-05</td>\n",
       "      <td>GRID02947</td>\n",
       "      <td>Landsat</td>\n",
       "      <td>2022-08-05</td>\n",
       "      <td>2022-08-05 00:22:51.440000+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020780</td>\n",
       "      <td>0.352657</td>\n",
       "      <td>2022-08-05 09:46:43.829840+00:00</td>\n",
       "      <td>2022-08-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRID02947_Landsat_2022-08-13</td>\n",
       "      <td>GRID02947</td>\n",
       "      <td>Landsat</td>\n",
       "      <td>2022-08-13</td>\n",
       "      <td>2022-08-13 00:22:22.858000+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065566</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2022-08-13 09:46:15.247840+00:00</td>\n",
       "      <td>2022-08-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image_id       name satellite        date  \\\n",
       "0  GRID02947_Landsat_2022-08-21  GRID02947   Landsat  2022-08-21   \n",
       "1  GRID02947_Landsat_2022-09-06  GRID02947   Landsat  2022-09-06   \n",
       "2  GRID02947_Landsat_2022-10-08  GRID02947   Landsat  2022-10-08   \n",
       "3  GRID02947_Landsat_2022-08-05  GRID02947   Landsat  2022-08-05   \n",
       "4  GRID02947_Landsat_2022-08-13  GRID02947   Landsat  2022-08-13   \n",
       "\n",
       "                           datetime  downloaded gcp_filepath  \\\n",
       "0  2022-08-21 00:22:44.081500+00:00       False          NaN   \n",
       "1  2022-09-06 00:22:45.466500+00:00       False          NaN   \n",
       "2  2022-10-08 00:22:46.536500+00:00       False          NaN   \n",
       "3  2022-08-05 00:22:51.440000+00:00       False          NaN   \n",
       "4  2022-08-13 00:22:22.858000+00:00       False          NaN   \n",
       "\n",
       "   cloud_probability    valids                    solardatetime    solarday  \\\n",
       "0           0.001414  1.000000 2022-08-21 09:46:36.471340+00:00  2022-08-21   \n",
       "1           0.948793  1.000000 2022-09-06 09:46:37.856340+00:00  2022-09-06   \n",
       "2           0.371418  1.000000 2022-10-08 09:46:38.926340+00:00  2022-10-08   \n",
       "3           0.020780  0.352657 2022-08-05 09:46:43.829840+00:00  2022-08-05   \n",
       "4           0.065566  1.000000 2022-08-13 09:46:15.247840+00:00  2022-08-13   \n",
       "\n",
       "   in_progress  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_download_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce338076-9d99-4567-81dc-5a6f89021f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2022c58b-5bed-4cfb-9f3c-ee45a95a241a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Model Inference Table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0002c113-5eb2-4c38-af7f-0eb0ef27441e",
   "metadata": {},
   "source": [
    "CREATE TABLE public.model_inference (\n",
    "\timage_id varchar NULL,\n",
    "\tname varchar NULL,\n",
    "\tsatellite varchar NULL,\n",
    "\t\"date\" date NULL,\n",
    "\tmodel_id varchar NULL,\n",
    "\tprediction varchar NULL,\n",
    "\tprediction_cont varchar NULL,\n",
    "\tprediction_vec varchar NULL,\n",
    "\tsession_data json NULL\n",
    ");\n",
    "\n",
    "ALTER TABLE public.model_inference ADD CONSTRAINT fk_modinf_image_id FOREIGN KEY (image_id) REFERENCES public.images_download(image_id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08cb708-d17a-4c50-b212-a2b2212448ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import pandas as pd\n",
    "import glob\n",
    "from google.cloud import storage\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58ea8a49-dab3-4c94-ac18-122e3a783d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem(\"gs\", requester_pays = True)\n",
    "client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0928e6-f9db-4bfa-889d-0d787c4021c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361e8c46b501407f849bc66e033a4c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#GRID\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "blobs = client.list_blobs(\"ml4floods_nema\", prefix = \"0_DEV/1_Staging/GRID\")\n",
    "\n",
    "files = [x.name for x in tqdm(blobs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4700ac1f-8b58-4947-87de-80dfd96da590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c08568e80e4c4e98433a13938ce1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sat_names = ['WF2_unet_rbgiswirs', 'WF2_unet_rbgiswirs_cont', 'WF2_unet_rbgiswirs_vec']\n",
    "\n",
    "results = defaultdict(dict)\n",
    "for f in tqdm(files):\n",
    "    m = f.split('/')\n",
    "    if not len(m) < 5:\n",
    "        m = m[3:]\n",
    "        if m[1] in sat_names:\n",
    "            name = m[0]\n",
    "            inf_type= m[1]\n",
    "            satellite = m[2]\n",
    "            date = m[3].split('.')[0]\n",
    "            file = m[3]\n",
    "            gcs_filepath = \"gs://ml4floods_nema/{}\".format(f)\n",
    "            image_id = \"_\".join([name, satellite, date])\n",
    "            \n",
    "            results[image_id][inf_type] = gcs_filepath\n",
    "            results[image_id].update(dict(image_id = image_id, name = name, satellite = satellite, date = date, model_id = \"WF2_unet_rbgiswirs\"))\n",
    "            \n",
    "            \n",
    "df = pd.DataFrame(results.values())\n",
    "df = df[['image_id', 'name', 'satellite', 'date', 'model_id', 'WF2_unet_rbgiswirs', 'WF2_unet_rbgiswirs_cont', 'WF2_unet_rbgiswirs_vec']]\n",
    "df.rename(columns={'WF2_unet_rbgiswirs' : 'prediction', 'WF2_unet_rbgiswirs_cont' : 'prediction_cont', 'WF2_unet_rbgiswirs_vec' : 'prediction_vec'}, inplace = True)\n",
    "\n",
    "dff['session_data'] = '{}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9836c3-31fe-4812-a95d-49c48ad1d89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ae24939-3c99-48a7-807d-9584ff062c4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Postprocessing Temporal"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0d0222c-058a-4a5c-9985-30adec03f06a",
   "metadata": {},
   "source": [
    "CREATE TABLE public.postproc_temporal (\n",
    "\tflooding_date_post_start date NOT NULL,\n",
    "\tflooding_date_post_end date NOT NULL,\n",
    "\tmodel_name varchar NULL,\n",
    "\tname varchar NOT NULL,\n",
    "\tpreflood varchar NULL,\n",
    "\tpostflood varchar NULL,\n",
    "\tprepostflood varchar NULL,\n",
    "\tflooding_date_pre_end date NOT NULL,\n",
    "\tflooding_date_pre_start date NULL,\n",
    "\tsession varchar(50) NULL,\n",
    "\tbucket varchar(50) NULL\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589e4579-4413-416b-baea-113f28820dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import pandas as pd\n",
    "import glob\n",
    "from google.cloud import storage\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ee3bc7-02db-4e52-86a1-79a493ab5c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem(\"gs\", requester_pays = True)\n",
    "client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b47a057-2fb7-4426-978e-4e01a6c49598",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2folder_file = \"gs://ml4floods_nema/0_DEV/1_Staging/operational/*/*/pre_post_products/*.geojson\"\n",
    "s2files = fs.glob(f\"{s2folder_file}\")\n",
    "# s2files = [f\"gs://{s2}\" for s2 in s2files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5d875e3-873e-4fbe-b9e0-b94751402d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "#Get all existing postprocessed geojsons from GCP, and split the files into pre, post, and prepost flood events, for every AOI. \n",
    "\n",
    "for file in s2files:\n",
    "    try:\n",
    "        if 'NEMA001' in file:\n",
    "            continue\n",
    "        bucket, _, _, _, session_code, name, _, fname = file.split('/')\n",
    "        flooding_date_pre_end_str, flooding_date_post_start_str, flooding_date_post_end_str = None, None, None\n",
    "        if 'prepostflood_' in fname:\n",
    "            flooding_date_pre_end_str = fname.split('_')[1]\n",
    "            flooding_date_post_start_str = fname.split('_')[2]\n",
    "            flooding_date_post_end_str = fname.split('_')[3].split('.')[0]\n",
    "            t = 'prepostflood'\n",
    "        elif 'preflood_' in fname:\n",
    "            flooding_date_pre_end_str = fname.split('_')[1].split('.')[0]\n",
    "            t = 'preflood'\n",
    "        elif 'postflood_' in fname:\n",
    "            flooding_date_post_start_str = fname.split('_')[1]\n",
    "            flooding_date_post_end_str = fname.split('_')[2].split('.')[0]\n",
    "            t = 'postflood'\n",
    "        rows.append({\"bucket\" : bucket, \"session\" : session_code, \"name\" : name, \"fname\" : fname, \n",
    "                    \"flooding_date_pre_end\" : flooding_date_pre_end_str, \"flooding_date_post_start\" : flooding_date_post_start_str, \n",
    "                     \"flooding_date_post_end\" : flooding_date_post_end_str,\n",
    "                     \"gs_fname\" : f\"gs://{file}\",\n",
    "                    'type' : t})\n",
    "    except Exception as e:\n",
    "        print(file, e)\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3f03d81-dd98-490e-be39-14dbd248c8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "\n",
    "df_merged = df.copy()\n",
    "\n",
    "grouped_df = df.groupby(['name', 'session'])\n",
    "\n",
    "for name, session_df in grouped_df:\n",
    "\n",
    "    prepostflood_rows = session_df[session_df['type'] == 'prepostflood']\n",
    "\n",
    "    for i, prepostflood_row in prepostflood_rows.iterrows():\n",
    "        preflood_row = session_df[(session_df['type'] == 'preflood') & (session_df['flooding_date_pre_end'] == prepostflood_row['flooding_date_pre_end'])].iloc[0]\n",
    "\n",
    "        postflood_row = session_df[(session_df['type'] == 'postflood') & (session_df['flooding_date_post_start'] == prepostflood_row['flooding_date_post_start']) & (session_df['flooding_date_post_end'] == prepostflood_row['flooding_date_post_end'])].iloc[0]\n",
    "\n",
    "        new_row = {\n",
    "            'name': name[0],\n",
    "            'session': name[1],\n",
    "            'bucket': prepostflood_row['bucket'],\n",
    "            'model_name' : 'WF2_unet_rbgiswirs',\n",
    "            # 'preflood_fname': preflood_row['fname'],\n",
    "            # 'postflood_fname': postflood_row['fname'],\n",
    "            'preflood': preflood_row['gs_fname'],\n",
    "            'postflood': postflood_row['gs_fname'],\n",
    "            'prepostflood' : prepostflood_row['gs_fname'],\n",
    "            'flooding_date_pre_start': np.nan,\n",
    "            'flooding_date_pre_end': preflood_row['flooding_date_pre_end'],\n",
    "            'flooding_date_post_start': postflood_row['flooding_date_post_start'],\n",
    "            'flooding_date_post_end': postflood_row['flooding_date_post_end']\n",
    "        }\n",
    "        new_rows.append(new_row)\n",
    "        \n",
    "df = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2dc05-07a2-45de-b269-42c199042c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "076e61df-782b-4264-bec8-f4f8cc64ff09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Postprocessing Spatial"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10a24a42-568f-4151-9813-3a72b91a908b",
   "metadata": {},
   "source": [
    "CREATE TABLE public.postproc_spatial (\n",
    "\tflooding_date_post_start date NOT NULL,\n",
    "\tflooding_date_post_end date NOT NULL,\n",
    "\tmodel_name varchar NULL,\n",
    "\taois _text NULL,\n",
    "\tpostflood varchar NULL,\n",
    "\tprepostflood varchar NULL,\n",
    "\tflooding_date_pre_end date NOT NULL,\n",
    "\tflooding_date_pre_start date NULL,\n",
    "\t\"session\" varchar NULL\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e632cb58-a3a7-4e24-b0ae-2935335a1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2folder_file = \"gs://ml4floods_nema/0_DEV/1_Staging/operational/NEMA002/*\"\n",
    "\n",
    "# grid_names = [x.split('/')[-1] for x in fs.glob(s2folder_file) if \"GRID\" in x.split('/')[-1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
